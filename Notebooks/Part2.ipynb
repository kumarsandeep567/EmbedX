{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3762b98e",
   "metadata": {},
   "source": [
    "# EmbedX: Multi-lingual Embedding Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfb71b5",
   "metadata": {},
   "source": [
    "## Project Overview\n",
    "\n",
    "- EmbedX is an Natural Language Processing project focused on developing and comparing different word embedding approaches across multiple languages. \n",
    "- The project aims to evaluate the effectiveness of various embedding techniques through practical applications in chatbot development and comprehensive comparative analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4375387f",
   "metadata": {},
   "source": [
    "## Key Components of this project\n",
    "\n",
    "- **Part 1.** Multi-lingual Word2Vec Implementation\n",
    "    - Focus on creating a model to produce Word2Vec embeddings for non-English languages.\n",
    "\n",
    "- **Part 2.** RNN-based Embedding Architecture \n",
    "    - Development of a custom RNN architecture for embedding generation. \n",
    "    - Comparative analysis against standard Keras Word2Vec embeddings.\n",
    "\n",
    "- **Part 3.** Chatbot Integration & Evaluation \n",
    "    - Development of an embedding-powered chatbot system.\n",
    "    - Comparative testing between English and non-English embedding models\n",
    "    - Performance benchmarking across different embedding sources\n",
    "\n",
    "\n",
    "- **Part 4.** Embedding Quality Assessment\n",
    "    - Comparative analysis of Word2Vec and RNN-based approaches\n",
    "    - Implementation of multiple evaluation metrics\n",
    "\n",
    "\n",
    "- **Part 5.** DNN Comparative Study\n",
    "    - Implementation of a shallow DNN for embedding generation\n",
    "    - Head-to-head comparison with RNN-based embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de3784d",
   "metadata": {},
   "source": [
    "## Priority Focus\n",
    "- The core focus is on developing and optimizing the RNN-based embedding architecture, as this forms the foundation for subsequent comparative analyses and applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c49d13b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d40977",
   "metadata": {},
   "source": [
    "## Part 2. RNN-based Embedding Architecture \n",
    "- Development of a custom RNN architecture for embedding generation. \n",
    "- Comparative analysis against standard Keras Word2Vec embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407a847f",
   "metadata": {},
   "source": [
    "### Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922ee3f3",
   "metadata": {},
   "source": [
    "- Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66d170ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from string import digits\n",
    "import pickle\n",
    "\n",
    "import re\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from indicnlp.tokenize import indic_tokenize\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Input\n",
    "from tensorflow.keras.models import Model, load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9657409",
   "metadata": {},
   "source": [
    "- Preprocess the text from the file \\\n",
    "Process the file line by line, remove unwanted characters, and breakdown the content into sentences based on Hindi punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c912447",
   "metadata": {},
   "outputs": [],
   "source": [
    "hi_punct = ['!', '?', '|', '||']\n",
    "sentences = []\n",
    "with open(\"dataset/Panchtantra.txt\", 'r', encoding=\"utf-8\") as file_data: \n",
    "    \n",
    "    sentence = ''\n",
    "    paragraph_p = 0\n",
    "    for l,line in enumerate(file_data): \n",
    "        \n",
    "        # Remove unwanted characters\n",
    "        line = line.strip() \\\n",
    "                    .replace('।', '') \\\n",
    "                    .replace('॥', '') \\\n",
    "                    .replace('\\ufeff', '') \\\n",
    "                    .replace('\\u200C', '') \\\n",
    "                    .replace('“', '') \\\n",
    "                    .replace('”', '') \\\n",
    "                    .replace('‘', '') \\\n",
    "                    .replace('’', '') \\\n",
    "                    .replace('—', '') \\\n",
    "                    .replace('-', '') \\\n",
    "                    .replace('$', '')\n",
    "                    \n",
    "        \n",
    "        # One \\n is just a carriage return. Two \\n's means \n",
    "        # a new paragraph, start a new sentence\n",
    "        if len(line) == 0:\n",
    "            #print('empty line!')\n",
    "            paragraph_p += 1\n",
    "            if paragraph_p == 2:\n",
    "                if 0 < len(sentence):\n",
    "                    sentences.append(sentence)\n",
    "                    sentence = ''\n",
    "                paragraph_p = 0\n",
    "            continue\n",
    "        \n",
    "        # detect sentence delimeters\n",
    "        delimeters = []\n",
    "        for c in hi_punct:\n",
    "            line_copy = copy.copy(line)\n",
    "            while -1 < line_copy.find(c):\n",
    "                d = line_copy.find(c)\n",
    "                delimeters.append(d)\n",
    "                line_copy = line_copy[:d] + '_' + line_copy[d+1:]\n",
    "                    \n",
    "        delimeters.sort()\n",
    "\n",
    "            \n",
    "        # no sentence delimeters: keep appending\n",
    "        if len(delimeters) == 0:\n",
    "            sentence += line\n",
    "            \n",
    "        # detected sentence delimeter(s), terminate sentence\n",
    "        else:\n",
    "                \n",
    "            last_index = 0\n",
    "            for i in delimeters:\n",
    "                sentence += line[last_index : i]\n",
    "                sentences.append(sentence)\n",
    "\n",
    "                sentence = ''\n",
    "                last_index = i + 1\n",
    "                    \n",
    "            # at the end of the indexes traversal, add remaining words to next sentence     \n",
    "            if last_index <= len(line):\n",
    "                dangling = line[last_index :].strip()\n",
    "                if 0 < len(dangling):\n",
    "                    sentence = dangling\n",
    "                    #print(\"seeding:\", sentence)\n",
    "                else:\n",
    "                    sentence = ''\n",
    "            else:\n",
    "                sentence = ''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f4c8eb",
   "metadata": {},
   "source": [
    "- Check the sentences list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0518d46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  'पंचतंत्र की कहानियांपंचतंत्र नीति, कथा और कहानियों का संग्रह है जिसके रचयिता आचार्य विष्णु शर्मा है पंचतंत्र की कहानी में बच्चोंके साथसाथ बड़े भी रुचि लेते हैं पंचतंत्र की कहानी के पीछे कोई ना कोई शिक्षा या मूल छिपा होता है जो हमें सीखदेती है पंचतंत्र की कहानी बच्चे बड़ी चाव से पढ़ते हैं तथा सीख लेते हैं पंचतंत्र की कछ कहानियां ऐसी भी है जोहिंदी में कहानी लेखन में दी जाती हैं तथा इसके साथसाथ कई परीक्षाओं में भी 80780 6 (9 कुछपाठयपृस्तक में दी होती है जो लिखने को आती हैं महत्वपूर्ण और आकर्षक 40 कहानियां इस ब्लॉग में दी गई हैं'),\n",
       " (1,\n",
       "  'आचार्य विष्ण शर्मासंस्कत के लेखक विष्णु शर्मा पंचतंत्र संस्कत की नीति पर्तक के लेखक माने जाते हैं जब यह ग्रंथ बनकर तैयारहुआ तब विष्ण शर्मा की उम्र 40 सात्र थी विष्ण शर्मा दक्षिण भारत के महिलारोप्य नामक नगर में रहते थे एकराजा के 3 मर्ख पत्र थे जिनकी जिम्मेदारी विष्ण शर्मा को दे दी गई विष्ण शर्मा को यह पता था कि यह इतने मूर्ख हैंकि इनको प्राने तरीकों से नहीं पढ़ाया जा सकता तब उन्होंने जंत कथाओं के द्वारा पढ़ाने का निश्चय कियापंचतंत्र को पांच समूह में बनाया गया जो 2000 साल पहले बना महामहोपाध्याय पं. सदाशिव शास्त्री के अनसारपंचतन्त्र के रचयिता विष्णशर्मा चाणक्य का ही दूसरा नाम था इसके आधार पर उनके अनुसार पंचतन्त्र की रचनाचन्द्रग॒प्त मौर्य के समय में ही हुई है और इसका रचना काल 300 ई.पू. माना जा सकता है'),\n",
       " (2,\n",
       "  'चालाक खटमलएक राजा के शयनकक्ष में मंदविसर्थिणी नाम की जूँ ने डेरा डाल रखा था रात को जब राजा जाता तो वह चपके सेबाहर निकलती और राजा का खून चूसकर, फिर अपने स्थान पर जा छिपतीसंयोग से एक दिन अग्निमख नामका एक खटमल भी राजा के शयनकक्ष में आ हक हँचा जूँ ने जब उसे देखा तो वहाँ से चले जाने को कहा उसे अपनेअधिकार क्षेत्र में किसी अन्य का दखल सहन नहीं था लेकिन खटमल भी कम चतर नहीं था, बोला, \"देखो,मेहमान से इस तरह बरताव नहीं किया जाता, आज रात मैं तम्हारा मेहमान हूँ\" जू अंतत: खटमल कीचिकनीचुपड़ी बातों में आ गई और उसे शरण देते हुए बोली, \"ठीक है, तुम यहा रातभर रुक सकते हो, लेकिन राजा'),\n",
       " (3, 'तो नहीं, उसका खून चूसने के लिए'),\n",
       " (4,\n",
       "  '\" खेंटमल बोला, \"लेकिन मैं तम्हारा मेहमान है, मझे कछ तो दोगीखाने लिए और राजा के खून से बढ़िया भोजन और क्या हो सकता है\" \"ठीक है\" जूँ बोली, \"तुम चुपचाप राजा काखून चूस लेना, उसे पीड़ा का एहसास नहीं होना चाहिए\" \\'जैसा तम कहोगी, बिल्कल वैसा ही होगा '),\n",
       " (5, '\" कहकरखटमल शयनकक्ष में राजा के आने की प्रतीक्षा करने लगा '),\n",
       " (6,\n",
       "  'रात ढलने पर राजा आया और बिस्तर पर पड़कर सोगया खटमल सबकछ भूलकर राजा को काटने दौड़ा और खून चूसने लगा ऐसा स्वादिष्ट खून उसने पहली बारचखा था, इसलिए वह जोरजोर से काटकर खून चूसने लगा इससे राजा के शरीर में तेज खुजली होने लगी औरउसकी नींद उचट गई  उसने क्रोध में भरकर अपने सेवकों से काटनेवाले जीव को दूँढ़कर मारने को कहायहसनकर चतर खटमल तो पलंग के पाए के नीचे छिप गया, लेकिन चादर के कोने पर बैठी जूँ राजा के सेवकों कीनजर में आ गई उन्होंने उसे पकड़ा और मार डालाशिक्षा : जाँचपरखकर के बाद ही अनजानों पर भरोसा करें'),\n",
       " (7,\n",
       "  'एक प्यासा कौंआएक बार एक कौआ था एक दिन वह बहुत प्यासा था वह पानी की तलाश में इधरउधर उड़ा उसने एक जगदेखा इसमें पानी थोड़ा था उसकी चोंचे पानी तक नहीं पहुँच सकी कौआ बहुत चतुर था उसने एक योजनासोची वह पत्थरों के कुछ टुकड़े लाया उसने उन्हें जग में डाले पानी ऊपर ओ गया उसने पानी पिया वह बहुतखुश हुआ वह उड़ गयाशिक्षा : बुद्धिमानी का फल मिलता है'),\n",
       " (8,\n",
       "  'संगठन में शक्ति हैएक बार एक बूढ़ा किसान था उसके चार पुत्र थे  एकदूसरे से सदैव झगड़ते थे उसने उन्हें नहीं झगडने कीसलाह दी, किन्तु सब व्यर्थ '),\n",
       " (9,\n",
       "  'एक दिन वह किसान बहुत बीमार हो गया उसने अपने पुत्रों को बुलाया उसने उन्हेंलकड़ियों का एक बंडल दिया उसने उनसे इसे तोड़ने को कहा '),\n",
       " (10,\n",
       "  'कोई भी इसे नहीं तोड़ सका उसने इस बंडल कोखोलने को कहा फिर किसान ने अपने लड़कों को लकड़ियाँ तोड़ने को कहा उन्होंने एकएक करके सरलता सेलकड़ियाँ तोड़ दीं अब किसान ने अपने लड़कों से कहा\"यदि तुम त्रकड़ियों के बंडल की तरह इकट्ठे (संगठित)रहोगे,कोई तुम्हें नुकसान नहीं पहुँचा सकता है '),\n",
       " (11,\n",
       "  'यदि तुम झगड़ोगे, कोई भी तुम्हें नुकसान पहुंचा सकता है\" उसकेलड़कों ने एक शिक्षा ली वे फिर कभी भी नहीं झगड़े किसान प्रसन्\\u200dन हुआ'),\n",
       " (12, 'शिक्षा : संगठन में शक्ति हैएक लालची कुत्ता'),\n",
       " (13, 'एक बार एक कुत्ता बहुत भूख था '),\n",
       " (14, ' वह भोजन की तलाश में इधर उधर गया '),\n",
       " (15,\n",
       "  'उसे कसाई की दुकान के पास हड्डीका एक टुकड़ा मिल्रा वहाँ पानी का एक नाला था नाले के ऊपर एक पुल था वह पुल को पार कर रहा था कुत्ते नेअपनी परछाई पानी में देखी कुत्ते ने सोचा कि हड्डी का टुकड़ा लिये कि यह दूसरा कुत्ता था कुत्ता लालची था वहइसे भी लेनाचाहता था वह उसकी तरफ भौंका '),\n",
       " (16,\n",
       "  'इसका टुकड़ा पानी में गिर गया वह बहुत दुःखी हुआशिक्षा : लालच बुरी बला है'),\n",
       " (17,\n",
       "  'एक चतुर टोपीविक्रेताएक बार एक टोपी विक्रेता था वह गाँवगाँव अपनी टोपिया बेचने जाता था एक बार जब वह एक गाँव पहुंचा तोरत त थक गया उसने अपनी टोकरी नीचे रखी और पेड़ के नीचे सो गया वृक्ष पर कुछ बंदर थे बंदर नीचें आयेउसकी टोपिर्चा ले गये '),\n",
       " (18,\n",
       "  'थोड़ी देर के पश्चात् टोपी विक्रेता जाग गया उसे अपनी टोपियाँ नहीं मिलीं उसनेऊपर देखा '),\n",
       " (19,\n",
       "  'उसने बंदरों को अपनी टोपियों के साथ देखा उसने एक योजना सोची उसने अपनी टोपी पहनी बंदरोंने भी ऐसा ही किया उसने अपनी टोपी जमीन पर फेंकी बंदरों ने भी ऐसा ही किया '),\n",
       " (20, 'उसने टोपियाँ एकत्र की वहचला गया वह बहुत प्रसन्\\u200dन था'),\n",
       " (21, 'शिक्षा : कभी हिम्मत मत हारोएक ईमानदार लकड़हारा'),\n",
       " (22,\n",
       "  'एक बार एक गरीब लकड़हारा था वह प्रतिदिन लकड़ी काटने जाता था एक दिन वह नदी के निकट लकड़ी काटरहा था उसकी कुल्हाड़ी नदी में गिर गई वह रोया और सहायता के लिए चिल्लााया जलदेवता प्रकट हुआ वहसोने की एक कल्हाड़ी लाया लकड़हारे ने इसे लेने से मनाकर दिया फिर देवता चाँदी की एक कुल्हाड़ी लाया उसने लकड़हार से उस कुल्हाड़ी को लेने को कहा उसने उसे भी लेने से मना कर दिया क्योंकि वह उसकी कुल्हाड़ीनहीं थी फिर जलदेवता उसकी असली कुल्हाड़ी लाया उसने लकडहारे से इसे लेने के लिये कहा उसने इसे ले लीजलदेवता उसकी इमानदारी पर बहुत खुश हुए  उसने तीनों कुल्हाड़ियाँ उसे दे दी वह बहुत प्रसन्\\u200dन हुआ औरदेवता को धन्यवाद दियाशिक्षा : ईमानदारी सबसे अच्छी नीति है'),\n",
       " (23,\n",
       "  'भूखी लोमड़ी/लोमड़ी और अंगूरएक बार एक लोमड़ी थी एक दिन वह बहुत भूखी था '),\n",
       " (24,\n",
       "  'वह भोजन की तलाश में इधरउधर गई वह अंगूरों के एकबगीचे में गई उसने पके हुए और मीठे अंगूरों का एक गुच्छा देखा वह प्रसन्\\u200dन हुई वह उन्हें खाना चाहती थीकिन्तु गुच्छा ऊँचा था लॉमड़ी उन तक नहीं पहुँच सकी वह इसकी ओर बारबार कूदी वह थक गई '),\n",
       " (25,\n",
       "  'वह उनकोनहीं पकड़ सकी वह चली गई उसने कहा, \"अंगूर खट्टे हैं\" वह बहुत दुःखी हुई शिक्षा : हाथ नहीं आने वाले अंगूरों को खट््टा बताया जाता है'),\n",
       " (26,\n",
       "  'एक गड़रिया जो झूठ बोलाएक बार एक गड़रिया लड़का था वह प्रत्येक दिन भेड़ों को मैदान में ले जाता था '),\n",
       " (27,\n",
       "  'एक दिन वह चिल्लाया\\'\" भेड़िया,भेड़िया, सहायता करो \" गाँव वाले दौड़े और वहाँ आये उन्होंने वहाँ भेड़िया नहीं देखा लड़का उन पर हँसा वेनाराज हुए और वापस लौट गये कुछ दिनों के बाद एक भेड़िया वहाँ आया लड़का सहायता के लिए बारबारचिल्लाया कोई नहीं आया भेड़िये ने लड़के को मार डाला'),\n",
       " (28,\n",
       "  'शिक्षा : एक बार का झूठा सदैव का झूठाखरगोश और शेरएक बार एक जंगल में एक शेर था वह बहुत से जानवरों को मारा करता था सभी जानवर शेर के पास दया केप्रार्थना करने गये शेर प्रतिदिन सबह एक जानवर चाहनः था वे इसके लिए सहमत हो गये एक दिन एकखरगोश की बारी थी उसने शेर को सजा देने की सोची वह शेर की गुफा में बहुत त देरी से पहुँचा शेर क्ॉदित हर आखरगोश ने कहा कि उसे एक अन्य शेर ने रो त्रिया था वह शेर उस दूसरे शेर को मार डालना चाहत था '),\n",
       " (29,\n",
       "  ']उसे एक कुएँ पर ले गया कुएँ में शेर ने अपनी परछाई देखी वह कुएं में कूद गया वह डूबकर मर गया जंगल केसभी जानवर खुश हुए'),\n",
       " (30, 'शिक्षा : बुद्धि ही बल है '),\n",
       " (31,\n",
       "  'रंगा सियारकिसी जंगल में एक सियार रहता था वह अपनी चालाकी के कारण अकेला रहता था एक रात खाने की तलाश मेंघूमताघूमता जंगल से बाहर निकल गया रात के उजाले में उसे नील से भरी एक बड़ी टंकी दिखाई दी उसने सोचाकि उसमें जरूर खाने की कोई चीज होगी वह टंकी पर उछल कर चढ़ गया उसने नील की टंकी में मूँह डालकरदेखा कि उसमें क्या है'),\n",
       " (32,\n",
       "  'टंकी थोड़ी खाली थी इसलिए उसने जैसे ही मुँह नीचे बढ़ाने की कोशिश की बैसे ही वह टंकीमें गिर पड़ा उसने टंकी से निकलने की बहत कोशिश की पर वह निकल नहीं सका '),\n",
       " (33,\n",
       "  'अन्त में वह किसी प्रकारबाहर निकला उसने पानी में अपना शरीर देखा, वह पूरा नीला था'),\n",
       " (34, 'सोचतेसोचते सियार जंगल में पहुँचा '),\n",
       " (35,\n",
       "  \"उसने अपने अन्य सियारों से कहा कि उसे कल रात वनदेवी मिली थीउन्होंने मुझे यह रूप दिया और जंगल का राजा बना दिया सभी उसकी बातों में आ गये सियार जंगल का राजाबन गया  एक बूढ़े सियार को उसकी बातों पर शक हुआ उसने कुछ सियारों के कान में कहा और उन सभी नेमिलकर 'हुआ हुआ' करना शुरू कर दिया रंगे सियार से भी नहीं रहा गया वह भी 'हुआहुआ' करने लगा \"),\n",
       " (36,\n",
       "  'इसप्रकार उसका भेदे खुल गया और जंगल के असली राजा सिंह द्वारा रंगा सियार मार डाला गयाशिक्षा न कभी असलियत को छुपाना चाहिए न छल्र करना चाहिएपंचतत्र की नईनई कहानियां'),\n",
       " (37, 'टपका का उरबरसात का दिन था चारों ओर पानी बरस रहा था '),\n",
       " (38, ' जंगल में बुढ़िया का घर भीग रहा था '),\n",
       " (39, 'जल्दी ही बुढ़िया का घरटपकने लगा '),\n",
       " (40, ' बुढ़िया परेशान हो उठी '),\n",
       " (41, ' परन्तु करती भी क्या '),\n",
       " (42, ' छप्पर को छाए कौन '),\n",
       " (43, 'थोड़ी देर में ओले भी पड़ने लगे '),\n",
       " (44, ' बेर बराबर ओले '),\n",
       " (45,\n",
       "  'उधर एक बाघ ओलों की मार से परेशान हो उठा  कूदतेफाँदतेवह बुढ़िया के घर के पास पहुँचा '),\n",
       " (46,\n",
       "  'बुढ़िया अन्दर चावल पका रही थी  चूल्हे पर पानी टपक रहा था, टपटप वहझुंझला उठी और बोली  \"मुझे टपका से इतना डर लगता है जितना बाघ से भी नहीं\"'),\n",
       " (47,\n",
       "  'बाघ ने सोचा बुढ़िया मुझसे तो नहीं डरती मगर टपका से डरती है जरूर टपका मुझसे भी बड़ा जानवर होगा बसइतना सोचते ही बाघ घबराया और सिर पर पैर रखकर भाग गया शिक्षा  मुसीबत के समय हमेशा चतुराई से काम करना चाहिए'),\n",
       " (48,\n",
       "  'चतुर चूहाएक चूहा था वह रास्ते पर जा रहा था उसे कपड़े का एक टुकड़ा मिल्रा वह उसे लेकर आगे बढ़ा '),\n",
       " (49, 'उसने एक दरजीकी दुकान देखी '),\n",
       " (50, 'दरजी के पास जाकर उसने कहा'),\n",
       " (51, 'चूहा : दरजी रे दरजी '),\n",
       " (52, ' इस कपड़े की टोपी सी दे '),\n",
       " (53, 'दरजी :यह कौन बोल रहा है '),\n",
       " (54, 'चूहा : मैं चूहा;, चूहा बोल रहा हूँ '),\n",
       " (55, ' इसकी एक टोपी सी दे चल..... रास्ता नाप '),\n",
       " (56,\n",
       "  'वरना कैंची उठाकर मारूँगादरजी : चलत्र... रास्ता नाप वरना कैची उठा कर मारूंगा '),\n",
       " (57, 'चूहा: अरे '),\n",
       " (58, 'तू मुझे डरा रहा है'),\n",
       " (59,\n",
       "  'कचहरी में जाऊँगा, सिपाही को बुलाऊँगा, तुझे खूब पिटवाऊँगा, और तमाशा देखूँगा यह सुन दरजी डर गया उसने झटपट टोपी सी दी '),\n",
       " (60,\n",
       "  'टोपी पहनकर चूहा आगे बढ़ा रास्ते में कशीदाकार की दुकान देखी चूहे को टोपी पर कशीदा कढ़ाने की इच्छा हुई'),\n",
       " (61, 'चूहा : भाई '),\n",
       " (62, ' मेरी टोपी पर थोड़ा कशीदा काढ़ दे कशीदाकार ने चूहे की ओर देखा '),\n",
       " (63, \"फिर उसे धमकाया और कहा'चल्र... चल... यहाँ किसे फुरसत है \"),\n",
       " (64, '\"'),\n",
       " (65,\n",
       "  'चूहा : अच्छा, तो तू भी मुझे भगा रहा है, लेकिन सुन,कचहरी में जाऊँगा, सिपाही को बुलाऊँगा, तुझे खूब पिटवारऊँगा, और तमाशा देखूगायह सुन कशीदाकार घबराया उसने चूहे को कचहरी में जाने से रोका उससे टोपी लेकर उस पर अच्छा कशीदा काढ़दिया चूहा तो खुश हो गया '),\n",
       " (66, 'शिक्षा: जीवन में किसी को भी छोटा नहीं समझना चाहिएलालची मित्र'),\n",
       " (67,\n",
       "  'किसी गाँव में दो मित्र रहते थे एक बार उन्होंने किसी दूसरी जगह जाकर धन कमाने की सोची दोनों यात्रा परनिकल पड़े रास्ते में जंगल पड़ता था जब वे जंगल से गुजर रहे थे, तो उन्हें एक भालू अपनी ओर आता दिखाईदिया दोनों मित्र डर गए उनमें से एक को पेड़ पर चढ़ना आता था. वह भालू से बचने के लिए पेड़ पर चढ़ गया, परदूसरा नीचे रह गया जब उसे भाल्रू से बचने का कोई रास्ता न सूझा तो साँस बंद करके जमीन पर लेट गया उसनेअपनी साँस को इस तरह रोक लिया मानो वह मर गया होभालू उसके नजदीक आया उसने जमीन पर लेटे हुए मित्र को सूँघा और उसे मरा हुआ जानकर चल्र दिया क्योंकिभालू मृत जीव को नहीं खाता जब भालू उसकी आँखों से ओझल हो गया तो वह उठे गया और तब पेड़ पर बैठा मित्रभी नीचे उतर आया उसने पूछा, मित्र'),\n",
       " (68,\n",
       "  'मुझे बेहद खुशी है कि तुम्हारी जान गई पर एक बात बता, भालू ने तेरेकान में क्या कहा'),\n",
       " (69,\n",
       "  '\"दूसरा मित्र अपने मित्र से पहले ही नाराज था वह उसे उसकी गलती का अहसास कराना चाहता था इसलिए बोला,\"मित्र भालू ने मुझे एक बहुत ही काम की बात कही है उसने कहा है कि ऐसे मित्र का साथ छोड़ दो, जो मुसीबत केसमय तुम्हारा साथ न दे और तुम्हें अकेला छोड़ जाए\" अपने मित्र की बात सुनकर पहला मित्र बहुत लज्जितहुआ'),\n",
       " (70,\n",
       "  'शिक्षासच्चे मित्र की पहचान विपत्ति में ही होती हैशरारती बंदर  एक्लालाधधा4 त (वध'),\n",
       " (71,\n",
       "  'एक समय की बात है , एक जंगल में एक शरारती बंदर रहा करता था वह बन्दर सभी को पेड़ों से फल फेक  फेककरके मारा करता था गर्मी का मौसम था पेड़ों पर खूब ढ़ेर सारे आम त्गे हुए थेबंदर सभी पेड़ों पर घूमघूमकर आमो का रस चूसता और खूब मजे करता'),\n",
       " (72,\n",
       "  'नीचे आने  जाने वाले जानवरों पर वह ऊपर से बैठेबैठे आम फैँक कर मारता और खूब हंसताएक समय हाथी उधर से गुजर रहा था'),\n",
       " (73,\n",
       "  'बंदर जो पेड़ पर बैठकर आम खा रहा था , वह अपने शरारती दिमाग से लाचार थाबन्दर ने हाथी पर आम तोड़कर माराएक आम हाथी के कान पर लगी और एक आम उसके आंख पर लगीइससे हाथी को गुस्सा आया उसने अपना सूंढ़ ऊपर उठाकर बंदर को गुस्से में लपेट लिया और कहा कि मैं आजतुझे मार डालूंगा तू सब को परेशान करता है इस पर बंदर ने अपने कान पकड़ लिए और माफी मांगी'),\n",
       " (74,\n",
       "  'अब से मैं किसी को परेशान नहीं करूंगा और किसी को शिकायत का मौका नहीं दूंगाबंदर के बार बार माफी मांगने और रोने पर हाथी को दया आ गई उसने बंदर को छोड़ दिया'),\n",
       " (75,\n",
       "  'कुछ समय बाद दोनों घनिष्ट मित्र हो गएबंदर अब अपने मित्र को फल तोड़  तोड़ कर खिलाता और दोनों मित्र पूरे जंगल में घूमते थे'),\n",
       " (76, 'शिक्षाकिसी को परेशान नहीं करना चाहिए उसका परिणाम बुरा ही होता है'),\n",
       " (77,\n",
       "  'सुंदरवन की कहानीसुंदरवन नामक एक खूबसूरत जंगल था वहां खूब ढ़ेर सारे जानवर , पशु  पक्षी रहा करते थे धीरे  धीरे सुंदरवनकी सुंदरता कम होती जा रही थी'),\n",
       " (78,\n",
       "  'पशुपक्षी भी वहां से कहीं दूसरे जंगल जा रहे थेकारण यह था कि वहां पर कुछ वर्षों से बरसात नहीं हो रही थीजिसके कारण जंगल में पानी की कमी निरंतर होती जा रही थी पेड़  पौधों की हरियाली खत्म हो रही थी , औरपशु पक्षियों का मन भी वहां नहीं लग रहा था'),\n",
       " (79,\n",
       "  'सभी वन को छोड़कर दूसरे वन में जा रहे थे कि गिद्धों ने ऊपर उड़ कर देखा तो उन्हें काले घने बादल जंगल कीओर आते नजर आएउन्होंने सभी को बताया कि जंगल की तरफ काले घने बादल आ रहे हैं , अब बारिश होगीइस पर सभी पशुपक्षी वापस सुंदरबन आ गए'),\n",
       " (80,\n",
       "  'देखते ही देखते कुछ देर में खूब बरसात हुईबरसात ईतनी हुई कि वह दोतीन दिन तक होती रही'),\n",
       " (81,\n",
       "  'सभी पशु पक्षी जब बरसात रुकने पर बाहर निकले तब उन्होंने देखा उनके तालाब और झील में खूब सारा पानी थासारे पेड़ पौधों पर नएनए पत्ते निकल आए थेइस पर सभी खुशी हुए और सभी ने उत्सव मनाया'),\n",
       " (82,\n",
       "  'सभी का मन प्रसन्\\u200dनता बत्तव अब झील मैं तैर रहे थे हिरण दौड़दौड़कर खुशियां मना रहे थे और ढेर सारे पप्पीहे दादुर मिलकर एक नए राग का अविष्कार कर रहे थेइस प्रकार सभी जानवर , पशु  पक्षी खुश थे अब उन्होंने दूसरे वन जाने का इरादा छोड़ दिया था और अपने घर मेंखुशी खुशी रहने लगे'),\n",
       " (83, 'शिक्षाधैर्य का फल मीठा होता हैचिड़ियाघर की सैर'),\n",
       " (84,\n",
       "  'अमन अपने मातापिता के साथ चिड़ियाघर की सैर करने जाता है अमन क्योंकि बच्चा है और वह अपनी मम्मीके गोदी में चलता है , इसलिए चिड़ियाघर में उसके लिए टिकट नहीं लगता मम्मी  पापा ने अपना टिकट लियाऔर वह तीनों मिल्रकर चिड़ियाघर के अंदर चले अमन ने चिड़ियाघर के अंदर देखा एक तालाब है उसमें ढेर सारेबत्तव और बगुला तैर रहे हैं उसे बहुत ही अच्छा लगा फिर उसने देखा एक बंदर है वह छोटेछोटे बंदरों को खिलारहा है , और उसके पीछे छोटे  छोटें बंदर भाग रहे हैं वह उसके पापा होंगे अमन ने फिर आगे एक भालू को देखाएक जिराफ को देखा और ढेर सारे शेर को भी देखा वह तेजतेज चिल्ला रहा था , छोटेछोटे बच्चे डर कर भाग रहेथेफिर चिंटू ने देखा एक हाथी का झुंड वहां पर खड़ा था और उसके छोटे  छोटे बच्चे भी वहां पर थे वह आपस मेंखेल रहे थे और इस तमाशे को वहां खड़े ढेर सारे बच्चे देख रहे थे अमन भी खड़ा हुआ और और हाथी के झुंड कोदिखने लगाओ जब वहां से चले तो अमन अपनी मम्मी के गोदी में नहीं चल रहा था'),\n",
       " (85,\n",
       "  'अमन ने देखा वहां छोटेछोटे बच्चे आए हैंवह अपने पैर पर चल रहे थे कोई भी अपने मम्मी  पापा के गोदी में नहीं चल रहा थाइस पर अमन भी अपने छोटेछोटे पैरों से चलने लगा इस पर अमन के मम्मी  पापा को बहुत खुशी हुई क्योंकिअब उसका बेटा चलना सीख रहा था')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i, s) for i,s in enumerate(sentences)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b7fbf3",
   "metadata": {},
   "source": [
    "- Preview the first 5 sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b84aef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['पंचतंत्र की कहानियांपंचतंत्र नीति, कथा और कहानियों का संग्रह है जिसके रचयिता आचार्य विष्णु शर्मा है पंचतंत्र की कहानी में बच्चोंके साथसाथ बड़े भी रुचि लेते हैं पंचतंत्र की कहानी के पीछे कोई ना कोई शिक्षा या मूल छिपा होता है जो हमें सीखदेती है पंचतंत्र की कहानी बच्चे बड़ी चाव से पढ़ते हैं तथा सीख लेते हैं पंचतंत्र की कछ कहानियां ऐसी भी है जोहिंदी में कहानी लेखन में दी जाती हैं तथा इसके साथसाथ कई परीक्षाओं में भी 80780 6 (9 कुछपाठयपृस्तक में दी होती है जो लिखने को आती हैं महत्वपूर्ण और आकर्षक 40 कहानियां इस ब्लॉग में दी गई हैं',\n",
       " 'आचार्य विष्ण शर्मासंस्कत के लेखक विष्णु शर्मा पंचतंत्र संस्कत की नीति पर्तक के लेखक माने जाते हैं जब यह ग्रंथ बनकर तैयारहुआ तब विष्ण शर्मा की उम्र 40 सात्र थी विष्ण शर्मा दक्षिण भारत के महिलारोप्य नामक नगर में रहते थे एकराजा के 3 मर्ख पत्र थे जिनकी जिम्मेदारी विष्ण शर्मा को दे दी गई विष्ण शर्मा को यह पता था कि यह इतने मूर्ख हैंकि इनको प्राने तरीकों से नहीं पढ़ाया जा सकता तब उन्होंने जंत कथाओं के द्वारा पढ़ाने का निश्चय कियापंचतंत्र को पांच समूह में बनाया गया जो 2000 साल पहले बना महामहोपाध्याय पं. सदाशिव शास्त्री के अनसारपंचतन्त्र के रचयिता विष्णशर्मा चाणक्य का ही दूसरा नाम था इसके आधार पर उनके अनुसार पंचतन्त्र की रचनाचन्द्रग॒प्त मौर्य के समय में ही हुई है और इसका रचना काल 300 ई.पू. माना जा सकता है',\n",
       " 'चालाक खटमलएक राजा के शयनकक्ष में मंदविसर्थिणी नाम की जूँ ने डेरा डाल रखा था रात को जब राजा जाता तो वह चपके सेबाहर निकलती और राजा का खून चूसकर, फिर अपने स्थान पर जा छिपतीसंयोग से एक दिन अग्निमख नामका एक खटमल भी राजा के शयनकक्ष में आ हक हँचा जूँ ने जब उसे देखा तो वहाँ से चले जाने को कहा उसे अपनेअधिकार क्षेत्र में किसी अन्य का दखल सहन नहीं था लेकिन खटमल भी कम चतर नहीं था, बोला, \"देखो,मेहमान से इस तरह बरताव नहीं किया जाता, आज रात मैं तम्हारा मेहमान हूँ\" जू अंतत: खटमल कीचिकनीचुपड़ी बातों में आ गई और उसे शरण देते हुए बोली, \"ठीक है, तुम यहा रातभर रुक सकते हो, लेकिन राजा',\n",
       " 'तो नहीं, उसका खून चूसने के लिए',\n",
       " '\" खेंटमल बोला, \"लेकिन मैं तम्हारा मेहमान है, मझे कछ तो दोगीखाने लिए और राजा के खून से बढ़िया भोजन और क्या हो सकता है\" \"ठीक है\" जूँ बोली, \"तुम चुपचाप राजा काखून चूस लेना, उसे पीड़ा का एहसास नहीं होना चाहिए\" \\'जैसा तम कहोगी, बिल्कल वैसा ही होगा ']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dca9cf8",
   "metadata": {},
   "source": [
    "- Convert sentences to a DataFrame for applying lambda functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3e0278f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>पंचतंत्र की कहानियांपंचतंत्र नीति, कथा और कहान...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>आचार्य विष्ण शर्मासंस्कत के लेखक विष्णु शर्मा ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>चालाक खटमलएक राजा के शयनकक्ष में मंदविसर्थिणी ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>तो नहीं, उसका खून चूसने के लिए</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\" खेंटमल बोला, \"लेकिन मैं तम्हारा मेहमान है, म...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>सभी पशु पक्षी जब बरसात रुकने पर बाहर निकले तब ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>सभी का मन प्रसन्‍नता बत्तव अब झील मैं तैर रहे ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>शिक्षाधैर्य का फल मीठा होता हैचिड़ियाघर की सैर</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>अमन अपने मातापिता के साथ चिड़ियाघर की सैर करने...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>अमन ने देखा वहां छोटेछोटे बच्चे आए हैंवह अपने ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0\n",
       "0   पंचतंत्र की कहानियांपंचतंत्र नीति, कथा और कहान...\n",
       "1   आचार्य विष्ण शर्मासंस्कत के लेखक विष्णु शर्मा ...\n",
       "2   चालाक खटमलएक राजा के शयनकक्ष में मंदविसर्थिणी ...\n",
       "3                      तो नहीं, उसका खून चूसने के लिए\n",
       "4   \" खेंटमल बोला, \"लेकिन मैं तम्हारा मेहमान है, म...\n",
       "..                                                ...\n",
       "81  सभी पशु पक्षी जब बरसात रुकने पर बाहर निकले तब ...\n",
       "82  सभी का मन प्रसन्‍नता बत्तव अब झील मैं तैर रहे ...\n",
       "83     शिक्षाधैर्य का फल मीठा होता हैचिड़ियाघर की सैर\n",
       "84  अमन अपने मातापिता के साथ चिड़ियाघर की सैर करने...\n",
       "85  अमन ने देखा वहां छोटेछोटे बच्चे आए हैंवह अपने ...\n",
       "\n",
       "[86 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_p = pd.DataFrame(sentences)\n",
    "sentences_p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02f6ed1",
   "metadata": {},
   "source": [
    "- Add spaces around punctuation marks for each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22ce94c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_p[0] = sentences_p[0].apply(lambda x: re.sub(r\"([!#$%&\\()*+,-./:;<=>?@[\\\\]^_`{|}~])\", r\" \\1 \", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11f42566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     पंचतंत्र की कहानियांपंचतंत्र नीति, कथा और कहान...\n",
       "1     आचार्य विष्ण शर्मासंस्कत के लेखक विष्णु शर्मा ...\n",
       "2     चालाक खटमलएक राजा के शयनकक्ष में मंदविसर्थिणी ...\n",
       "3                        तो नहीं, उसका खून चूसने के लिए\n",
       "4     \" खेंटमल बोला, \"लेकिन मैं तम्हारा मेहमान है, म...\n",
       "                            ...                        \n",
       "81    सभी पशु पक्षी जब बरसात रुकने पर बाहर निकले तब ...\n",
       "82    सभी का मन प्रसन्‍नता बत्तव अब झील मैं तैर रहे ...\n",
       "83       शिक्षाधैर्य का फल मीठा होता हैचिड़ियाघर की सैर\n",
       "84    अमन अपने मातापिता के साथ चिड़ियाघर की सैर करने...\n",
       "85    अमन ने देखा वहां छोटेछोटे बच्चे आए हैंवह अपने ...\n",
       "Name: 0, Length: 86, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_p[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926a1766",
   "metadata": {},
   "source": [
    "- Remove digits from the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ede8865d",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_digits = str.maketrans('', '', digits)\n",
    "sentences_p[0] = sentences_p[0].apply(lambda x: x.translate(remove_digits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b88c76f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     पंचतंत्र की कहानियांपंचतंत्र नीति, कथा और कहान...\n",
       "1     आचार्य विष्ण शर्मासंस्कत के लेखक विष्णु शर्मा ...\n",
       "2     चालाक खटमलएक राजा के शयनकक्ष में मंदविसर्थिणी ...\n",
       "3                        तो नहीं, उसका खून चूसने के लिए\n",
       "4     \" खेंटमल बोला, \"लेकिन मैं तम्हारा मेहमान है, म...\n",
       "                            ...                        \n",
       "81    सभी पशु पक्षी जब बरसात रुकने पर बाहर निकले तब ...\n",
       "82    सभी का मन प्रसन्‍नता बत्तव अब झील मैं तैर रहे ...\n",
       "83       शिक्षाधैर्य का फल मीठा होता हैचिड़ियाघर की सैर\n",
       "84    अमन अपने मातापिता के साथ चिड़ियाघर की सैर करने...\n",
       "85    अमन ने देखा वहां छोटेछोटे बच्चे आए हैंवह अपने ...\n",
       "Name: 0, Length: 86, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_p[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914dea32",
   "metadata": {},
   "source": [
    "- Remove single quotes from the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f90b7d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove quotes, saveguard commas:\n",
    "sentences_p[0] = sentences_p[0].apply(lambda x: re.sub(\"'\", '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca7dce8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     पंचतंत्र की कहानियांपंचतंत्र नीति, कथा और कहान...\n",
       "1     आचार्य विष्ण शर्मासंस्कत के लेखक विष्णु शर्मा ...\n",
       "2     चालाक खटमलएक राजा के शयनकक्ष में मंदविसर्थिणी ...\n",
       "3                        तो नहीं, उसका खून चूसने के लिए\n",
       "4     \" खेंटमल बोला, \"लेकिन मैं तम्हारा मेहमान है, म...\n",
       "                            ...                        \n",
       "81    सभी पशु पक्षी जब बरसात रुकने पर बाहर निकले तब ...\n",
       "82    सभी का मन प्रसन्‍नता बत्तव अब झील मैं तैर रहे ...\n",
       "83       शिक्षाधैर्य का फल मीठा होता हैचिड़ियाघर की सैर\n",
       "84    अमन अपने मातापिता के साथ चिड़ियाघर की सैर करने...\n",
       "85    अमन ने देखा वहां छोटेछोटे बच्चे आए हैंवह अपने ...\n",
       "Name: 0, Length: 86, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_p[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0966961",
   "metadata": {},
   "source": [
    "- Remove double quotes from the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b944f7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_p[0] = sentences_p[0].apply(lambda x: re.sub('\"', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d656e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     पंचतंत्र की कहानियांपंचतंत्र नीति, कथा और कहान...\n",
       "1     आचार्य विष्ण शर्मासंस्कत के लेखक विष्णु शर्मा ...\n",
       "2     चालाक खटमलएक राजा के शयनकक्ष में मंदविसर्थिणी ...\n",
       "3                        तो नहीं, उसका खून चूसने के लिए\n",
       "4      खेंटमल बोला, लेकिन मैं तम्हारा मेहमान है, मझे...\n",
       "                            ...                        \n",
       "81    सभी पशु पक्षी जब बरसात रुकने पर बाहर निकले तब ...\n",
       "82    सभी का मन प्रसन्‍नता बत्तव अब झील मैं तैर रहे ...\n",
       "83       शिक्षाधैर्य का फल मीठा होता हैचिड़ियाघर की सैर\n",
       "84    अमन अपने मातापिता के साथ चिड़ियाघर की सैर करने...\n",
       "85    अमन ने देखा वहां छोटेछोटे बच्चे आए हैंवह अपने ...\n",
       "Name: 0, Length: 86, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_p[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7135ba7",
   "metadata": {},
   "source": [
    "- Tokenize sentences into words using Indic NLP tokenizer \\\n",
    "Separate each token with a space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7453e18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_p[0] = sentences_p[0].apply(lambda x: \" \".join(indic_tokenize.trivial_tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3accceea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     पंचतंत्र की कहानियांपंचतंत्र नीति , कथा और कहा...\n",
       "1     आचार्य विष्ण शर्मासंस्कत के लेखक विष्णु शर्मा ...\n",
       "2     चालाक खटमलएक राजा के शयनकक्ष में मंदविसर्थिणी ...\n",
       "3                       तो नहीं , उसका खून चूसने के लिए\n",
       "4     खेंटमल बोला , लेकिन मैं तम्हारा मेहमान है , मझ...\n",
       "                            ...                        \n",
       "81    सभी पशु पक्षी जब बरसात रुकने पर बाहर निकले तब ...\n",
       "82    सभी का मन प्रसन्‍नता बत्तव अब झील मैं तैर रहे ...\n",
       "83       शिक्षाधैर्य का फल मीठा होता हैचिड़ियाघर की सैर\n",
       "84    अमन अपने मातापिता के साथ चिड़ियाघर की सैर करने...\n",
       "85    अमन ने देखा वहां छोटेछोटे बच्चे आए हैंवह अपने ...\n",
       "Name: 0, Length: 86, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences_p)\n",
    "sentences_p[0][:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e73ac06",
   "metadata": {},
   "source": [
    "- Preprocess each sentence with `<start>` and `<end>` tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a8b3b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(w):\n",
    "    w = w.strip()\n",
    "\n",
    "    # adding a start and an end token to the sentence\n",
    "    # so that the model know when to start and stop predicting.\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2d2464",
   "metadata": {},
   "source": [
    "- Create a dataset from preprocessed sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a06a66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence_no_tags(w):\n",
    "    w = w.strip()\n",
    "\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32e1226e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(start, end):\n",
    "    #sentence_pairs = [[preprocess_sentence_no_tags(l[0]), preprocess_sentence(l[1])] for l in lines[start:end].values]\n",
    "    sentences_preprocessed = [preprocess_sentence(l) for l in sentences_p[0][start:end]]\n",
    "    #return zip(*sentence_pairs)\n",
    "    return sentences_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83f9681f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_full_dataset():\n",
    "    #sentence_pairs = [[preprocess_sentence_no_tags(l[0]), preprocess_sentence(l[1])] for l in lines.values]\n",
    "    sentences_preprocessed = [preprocess_sentence(l) for l in sentences_p[0]]\n",
    "    return sentences_preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd2f72b",
   "metadata": {},
   "source": [
    "- Tokenize the sentences into sequences of integers using TensorFlow's `Tokenizer` \\ \n",
    "- Ensure the sequences are then padded to maintain uniform length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71cae931",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "\n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "\n",
    "    return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0280a4",
   "metadata": {},
   "source": [
    "- Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7dbc97a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(start, end):\n",
    "    # creating cleaned input, output pairs\n",
    "    #inp_lang, targ_lang = create_dataset(start, end)\n",
    "    inp_lang = create_dataset(start, end)\n",
    "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
    "\n",
    "    return input_tensor, inp_lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7f3235b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_full_dataset():\n",
    "    # creating cleaned input, output pairs\n",
    "    inp_lang = create_full_dataset()\n",
    "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
    "\n",
    "    return input_tensor, inp_lang_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25b1c00",
   "metadata": {},
   "source": [
    "- Preview a sentence from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "807c8d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> अमन ने देखा वहां छोटेछोटे बच्चे आए हैंवह अपने पैर पर चल रहे थे कोई भी अपने मम्मी पापा के गोदी में नहीं चल रहा थाइस पर अमन भी अपने छोटेछोटे पैरों से चलने लगा इस पर अमन के मम्मी पापा को बहुत खुशी हुई क्योंकिअब उसका बेटा चलना सीख रहा था <end>\n"
     ]
    }
   ],
   "source": [
    "zh = create_full_dataset()\n",
    "print(zh[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6821a61",
   "metadata": {},
   "source": [
    "- Load a subset of the dataset (sentences from index 1 to 40), and tokenize them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ddaed172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_examples_p = 40 \n",
    "input_tensor_p, inp_lang_p  = load_dataset(1, 40)\n",
    "\n",
    "# Calculate max_length of the target tensors\n",
    "max_length_inp_p = input_tensor_p.shape[1]\n",
    "max_length_inp_p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa2e287",
   "metadata": {},
   "source": [
    "- Creating training and validation sets using an 90-10 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c628e339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, 4)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor_train_p, input_tensor_val_p = train_test_split(input_tensor_p, test_size=0.1)\n",
    "\n",
    "# Show length\n",
    "len(input_tensor_train_p), len(input_tensor_val_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95ab69d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_examples = len(sentences_p[0])\n",
    "input_tensor, inp_lang = load_full_dataset()\n",
    "\n",
    "# Calculate max_length of the target tensors\n",
    "max_length_inp = input_tensor.shape[1]\n",
    "max_length_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "902000e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86, 188)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0d100120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77, 9)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating training and validation sets using an 90-10 split\n",
    "input_tensor_train, input_tensor_val = train_test_split(input_tensor, test_size=0.1)\n",
    "\n",
    "# Show length\n",
    "len(input_tensor_train), len(input_tensor_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a58ddb",
   "metadata": {},
   "source": [
    "- Checking word to index mapping in the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "508cb3e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'इस'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_lang.index_word[60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aefffd38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_lang.word_index['इस']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2855b9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(lang, tensor):\n",
    "    for t in tensor:\n",
    "        if t!=0:\n",
    "            print (\"%d ----> %s\" % (t, lang.index_word[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d968ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "1 ----> <start>\n",
      "178 ----> चतुर\n",
      "793 ----> चूहाएक\n",
      "50 ----> चूहा\n",
      "6 ----> था\n",
      "5 ----> वह\n",
      "206 ----> रास्ते\n",
      "12 ----> पर\n",
      "62 ----> जा\n",
      "22 ----> रहा\n",
      "6 ----> था\n",
      "21 ----> उसे\n",
      "329 ----> कपड़े\n",
      "16 ----> का\n",
      "3 ----> एक\n",
      "132 ----> टुकड़ा\n",
      "273 ----> मिल्रा\n",
      "5 ----> वह\n",
      "21 ----> उसे\n",
      "330 ----> लेकर\n",
      "207 ----> आगे\n",
      "331 ----> बढ़ा\n",
      "2 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "print (\"Input Language; index to word mapping\")\n",
    "convert(inp_lang, input_tensor_train[30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "de16068c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77, 188)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f01c57",
   "metadata": {},
   "source": [
    "- Create TensorFlow datasets for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f77d8f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "\n",
    "vocab_inp_size = len(inp_lang.word_index) + 1\n",
    "\n",
    "dataset_train = tf.data.Dataset.from_tensor_slices(input_tensor_train).shuffle(BUFFER_SIZE)\n",
    "dataset_train = dataset_train.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset_val = tf.data.Dataset.from_tensor_slices(input_tensor_val).shuffle(BUFFER_SIZE)\n",
    "dataset_val = dataset_val.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699b669e",
   "metadata": {},
   "source": [
    "- Custom data generator that can be used for batching and shuffling data in training \n",
    "- Yield batches of data (of size batch_size) for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b6d2b4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(data, min_index, max_index, shuffle=False, batch_size=128):\n",
    "    if max_index is None:\n",
    "        max_index = len(data) - 1\n",
    "    i = min_index\n",
    "    \n",
    "    while True:\n",
    "        if i + batch_size >= max_index:\n",
    "            i = min_index\n",
    "        rows = np.arange(i, min(i + batch_size, max_index))\n",
    "        i += len(rows)\n",
    "\n",
    "        # preallocate\n",
    "        samples = np.zeros((len(rows), data.shape[-1])) #1st dim:rows, 2nd dim:features\n",
    "        \n",
    "        # fill in: For each row selected, select the number of timesteps to sample from\n",
    "        for j, row in enumerate(rows):                         # for each observation (row)\n",
    "            indices = rows[j]\n",
    "            samples[j] = data[indices]\n",
    "            \n",
    "        yield samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3e9ef13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE_P = 4\n",
    "BUFFER_SIZE_P = len(input_tensor_train_p)\n",
    "\n",
    "inp_gen_p = generator(\n",
    "    input_tensor_train_p,\n",
    "    min_index   = 0,\n",
    "    max_index   = 39,\n",
    "    batch_size  = BATCH_SIZE_P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "25d821fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 137)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch_p = next(inp_gen_p)\n",
    "example_input_batch_p.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffbdcd0",
   "metadata": {},
   "source": [
    "- Preview index mappings of generated input batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1f2f9bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.,  43.,  26.,   2.,  27.,  14., 534., 153.,  14., 535.,  16.,\n",
       "        536.,  27.,   2.,  32.,   7.,   2.,  29.,   4.,   1.,  22.,  12.,\n",
       "        537.,   9., 538., 539.,   4., 110., 111.,  29.,   6., 163., 540.,\n",
       "        541.,  95.,  61.,  29., 180., 542.,   2., 111., 543.,   4., 161.,\n",
       "        122.,  56., 544.,  70.,  61.,   2.,  31., 545.,  10., 546.,  48.,\n",
       "          8.,  29.,   9., 547., 548.,  10., 178.,   1.,  29.,  10., 549.,\n",
       "          7.,  22., 172., 550.,  12., 101.,  29., 551., 552., 553.,  21.,\n",
       "         25.,  36.,  20.,   2.,  89.,  29.,  21., 554., 555.,   4.,   1.,\n",
       "         29., 184., 556.,  29.,   9.,  72., 557., 558.,   4.,   5.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.],\n",
       "       [  3.,   2., 142., 363.,  27.,   2., 143.,   4.,   2.,  31.,   1.,\n",
       "         22., 142.,   4.,   1.,  28.,  10.,  73.,   7., 144., 364.,   8.,\n",
       "          2., 365., 366.,  28., 367.,   4.,  33., 368.,  28., 145.,  13.,\n",
       "        146.,  98., 143.,  22., 147.,   4.,   8.,   2., 369.,   1., 370.,\n",
       "          6.,  74., 371.,  75.,   8.,  99., 372.,   7., 373.,  28., 148.,\n",
       "        374.,  15.,   8.,  28., 375.,   1., 376.,  35.,   1., 377., 149.,\n",
       "         26., 378.,  14., 379., 380.,  18.,   5.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.],\n",
       "       [  3., 187., 106., 496., 106.,  16., 497.,  27.,   2., 106.,  48.,\n",
       "          2.,  31.,   1.,  22., 187.,   4.,   5.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.],\n",
       "       [  3.,  37., 323.,  17.,  19.,  96.,  16., 324.,  17., 325., 326.,\n",
       "         53., 327., 328.,  19.,   9., 137., 329.,  16.,  39.,  93.,  57.,\n",
       "         97., 330.,  39.,   8., 331., 332.,   4.,  11., 138.,   1., 333.,\n",
       "         12., 334.,  39.,  93.,  57., 335.,  19.,   6., 139.,   7., 336.,\n",
       "        337., 338., 339., 340., 341., 342.,  30.,   8., 343.,   7., 344.,\n",
       "         40., 140.,  12., 345., 346.,   9., 347., 348.,   9., 349., 125.,\n",
       "         53.,  51., 350.,   6., 351.,   6.,  71., 352.,  15.,  11.,  68.,\n",
       "        353.,   6., 354.,  17., 355.,  66.,  19.,   6., 140., 356.,   7.,\n",
       "         67.,  30.,  65.,  20., 357.,  16.,  72., 358.,  26., 359.,   6.,\n",
       "        141.,  24., 360.,  17., 361., 362.,   5.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "95c3325b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[  1   5 664 ...   0   0   0]\n",
      " [  1  14  28 ...   0   0   0]\n",
      " [  1 188 189 ...   0   0   0]\n",
      " ...\n",
      " [  1  58  20 ...   0   0   0]\n",
      " [  1  38  16 ...   0   0   0]\n",
      " [  1   3  36 ...   0   0   0]], shape=(64, 188), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for (batch, inp) in enumerate(dataset_train):\n",
    "    print(inp)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d038cb09",
   "metadata": {},
   "source": [
    "### Building an RNN model to generate vector embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f7da71",
   "metadata": {},
   "source": [
    "We create a RNN model for creating the vector embeddings for our Hindi text\n",
    "\n",
    "- It starts with an embedding layer to convert words into dense vectors, followed by two LSTM layers to learn sequential patterns. \n",
    "- The output layer predicts the next word in the sequence, using a `softmax` activation. \n",
    "- The model uses the `Adam` optimizer and `sparse_categorical_crossentropy` loss for classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5aa964ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_hindi_rnn_model(vocab_size, max_sequence_length, embedding_dim = 100, rnn_units = 256):\n",
    "    # Input layer with fixed sequence length\n",
    "    inputs = Input(shape=(max_sequence_length,))\n",
    "    \n",
    "    # Embedding layer\n",
    "    embedding = Embedding(vocab_size, embedding_dim)(inputs)\n",
    "    \n",
    "    # LSTM layers\n",
    "    lstm1 = LSTM(rnn_units, return_sequences=True)(embedding)\n",
    "    lstm2 = LSTM(rnn_units)(lstm1)\n",
    "    \n",
    "    # Output layer to predict next word\n",
    "    outputs = Dense(vocab_size, activation='softmax')(lstm2)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(\n",
    "        optimizer   = 'adam',\n",
    "        loss        = 'sparse_categorical_crossentropy',\n",
    "        metrics     = ['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c85587d",
   "metadata": {},
   "source": [
    "- To prepare the training data for the RNN model, we create a sliding windows of words. \n",
    "- Each window of `window_size` words is used as input X, and the next word in the sequence is the target y. \n",
    "- Sequences shorter than window_size + 1 are ignored, and padding is applied to maintain consistent window size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "347b62d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training_data(sequences, window_size=5):\n",
    "    X, y = [], []\n",
    "    \n",
    "    for sequence in sequences:\n",
    "        # Skip sequences shorter than window_size + 1\n",
    "        if len(sequence) < window_size + 1:\n",
    "            continue\n",
    "            \n",
    "        # Filter out padding (zeros)\n",
    "        sequence = [x for x in sequence if x != 0]\n",
    "        \n",
    "        for i in range(len(sequence) - window_size):\n",
    "            window = sequence[i:i + window_size]\n",
    "            target = sequence[i + window_size]\n",
    "            \n",
    "            # Pad window if necessary\n",
    "            if len(window) < window_size:\n",
    "                window = window + [0] * (window_size - len(window))\n",
    "            \n",
    "            X.append(window)\n",
    "            y.append(target)\n",
    "    \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b8afc9",
   "metadata": {},
   "source": [
    "- Train the model with 90-10 size for validation data with batch size of 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2e215c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X, y, validation_split=0.1, epochs=50, batch_size=64):\n",
    "    try:\n",
    "        history = model.fit(\n",
    "            X, \n",
    "            y,\n",
    "            validation_split = validation_split,\n",
    "            epochs           = epochs,\n",
    "            batch_size       = batch_size,\n",
    "            verbose          = 1\n",
    "        )\n",
    "        return history\n",
    "    except Exception as e:\n",
    "        # Debugging\n",
    "        print(f\"Error during training: {str(e)}\")\n",
    "        print(f\"Input shape: {X.shape}\")\n",
    "        print(f\"Target shape: {y.shape}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0da8c4f",
   "metadata": {},
   "source": [
    "- Return the weights of that layer, which correspond to the word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "26591555",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(model):\n",
    "    return model.get_layer(index = 1).get_weights()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac04b32d",
   "metadata": {},
   "source": [
    "- Return the vector corresponding to the given word index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "665398e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_embedding(model, word_idx):\n",
    "    embeddings = get_embeddings(model)\n",
    "    return embeddings[word_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936e6f74",
   "metadata": {},
   "source": [
    "- Finds the top `k` most similar words to a given word, based on cosine similarity between their embeddings\n",
    "- Compare the word's embedding with all other embeddings and return the `k` words with the highest similarity\n",
    "- Return the words if tokenizer is available, else return the indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "507a6af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_words(model, word_idx, top_k=5, tokenizer=None):\n",
    "    embeddings = get_embeddings(model)\n",
    "    word_embedding = embeddings[word_idx]\n",
    "    \n",
    "    # Find similar words by using cosine similarity\n",
    "    similarities = np.dot(embeddings, word_embedding) / (\n",
    "        np.linalg.norm(embeddings, axis=1) * np.linalg.norm(word_embedding)\n",
    "    )\n",
    "    \n",
    "    # Get top k similar words\n",
    "    top_indices = np.argsort(similarities)[-top_k-1:][::-1][1:]\n",
    "    \n",
    "    if tokenizer:\n",
    "        return [(tokenizer.index_word[idx], similarities[idx]) for idx in top_indices]\n",
    "    \n",
    "    return [(idx, similarities[idx]) for idx in top_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01b75ee",
   "metadata": {},
   "source": [
    "### Train the RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "88066e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_hindi_rnn_embeddings(input_tensor_train, vocab_inp_size, inp_lang, max_sequence_length):\n",
    "    \n",
    "    # Initialize the model with fixed sequence length\n",
    "    model = build_hindi_rnn_model(\n",
    "        vocab_size          = vocab_inp_size,\n",
    "        max_sequence_length = max_sequence_length,\n",
    "        embedding_dim       = 100,\n",
    "        rnn_units           = 256\n",
    "    )\n",
    "    \n",
    "    # Prepare training data\n",
    "    X_train, y_train = prepare_training_data(input_tensor_train)\n",
    "    \n",
    "    # Train the model\n",
    "    print(\"Starting training...\")\n",
    "    history = train_model(model, X_train, y_train, epochs=50)\n",
    "\n",
    "    # Save the model\n",
    "    model.save(\"models/Part2.h5\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8b77c3",
   "metadata": {},
   "source": [
    "- Train, save, and load RNN model on the input data. \n",
    "- Retrieve the embedding for the word \"कहानी\", and also find and print the most similar words to \"कहानी\" based on cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "035955b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch 1/50\n",
      "36/36 [==============================] - 5s 24ms/step - loss: 6.6810 - accuracy: 0.0214 - val_loss: 6.2923 - val_accuracy: 0.0472\n",
      "Epoch 2/50\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 6.1304 - accuracy: 0.0192 - val_loss: 6.5288 - val_accuracy: 0.0039\n",
      "Epoch 3/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 5.9904 - accuracy: 0.0262 - val_loss: 6.7623 - val_accuracy: 0.0472\n",
      "Epoch 4/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.9320 - accuracy: 0.0236 - val_loss: 6.9386 - val_accuracy: 0.0472\n",
      "Epoch 5/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.8838 - accuracy: 0.0284 - val_loss: 6.9717 - val_accuracy: 0.0079\n",
      "Epoch 6/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.8441 - accuracy: 0.0306 - val_loss: 6.9422 - val_accuracy: 0.0512\n",
      "Epoch 7/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.8061 - accuracy: 0.0332 - val_loss: 6.9722 - val_accuracy: 0.0118\n",
      "Epoch 8/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 5.7206 - accuracy: 0.0389 - val_loss: 7.1844 - val_accuracy: 0.0197\n",
      "Epoch 9/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 5.6077 - accuracy: 0.0381 - val_loss: 7.4309 - val_accuracy: 0.0157\n",
      "Epoch 10/50\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 5.5023 - accuracy: 0.0420 - val_loss: 7.3052 - val_accuracy: 0.0157\n",
      "Epoch 11/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 5.3999 - accuracy: 0.0512 - val_loss: 7.5979 - val_accuracy: 0.0315\n",
      "Epoch 12/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.3052 - accuracy: 0.0547 - val_loss: 7.5706 - val_accuracy: 0.0315\n",
      "Epoch 13/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 5.1683 - accuracy: 0.0608 - val_loss: 7.6645 - val_accuracy: 0.0197\n",
      "Epoch 14/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 5.0280 - accuracy: 0.0713 - val_loss: 7.9002 - val_accuracy: 0.0315\n",
      "Epoch 15/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 4.8613 - accuracy: 0.0779 - val_loss: 8.0067 - val_accuracy: 0.0236\n",
      "Epoch 16/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 4.7171 - accuracy: 0.0818 - val_loss: 8.1811 - val_accuracy: 0.0197\n",
      "Epoch 17/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 4.5466 - accuracy: 0.0954 - val_loss: 8.2982 - val_accuracy: 0.0236\n",
      "Epoch 18/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 4.3703 - accuracy: 0.1102 - val_loss: 8.3890 - val_accuracy: 0.0276\n",
      "Epoch 19/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 4.2114 - accuracy: 0.1212 - val_loss: 8.4638 - val_accuracy: 0.0157\n",
      "Epoch 20/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 4.0209 - accuracy: 0.1360 - val_loss: 8.6577 - val_accuracy: 0.0276\n",
      "Epoch 21/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 3.8641 - accuracy: 0.1492 - val_loss: 8.6177 - val_accuracy: 0.0157\n",
      "Epoch 22/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 3.6662 - accuracy: 0.1855 - val_loss: 8.8475 - val_accuracy: 0.0197\n",
      "Epoch 23/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 3.4906 - accuracy: 0.2139 - val_loss: 8.8505 - val_accuracy: 0.0157\n",
      "Epoch 24/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 3.3037 - accuracy: 0.2345 - val_loss: 9.0113 - val_accuracy: 0.0197\n",
      "Epoch 25/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 3.1160 - accuracy: 0.2712 - val_loss: 9.0008 - val_accuracy: 0.0197\n",
      "Epoch 26/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 2.9321 - accuracy: 0.3123 - val_loss: 9.1594 - val_accuracy: 0.0079\n",
      "Epoch 27/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 2.7699 - accuracy: 0.3294 - val_loss: 9.3026 - val_accuracy: 0.0236\n",
      "Epoch 28/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 2.6045 - accuracy: 0.3906 - val_loss: 9.3261 - val_accuracy: 0.0118\n",
      "Epoch 29/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 2.4572 - accuracy: 0.4287 - val_loss: 9.4664 - val_accuracy: 0.0157\n",
      "Epoch 30/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 2.2781 - accuracy: 0.4654 - val_loss: 9.5384 - val_accuracy: 0.0157\n",
      "Epoch 31/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 2.1138 - accuracy: 0.5236 - val_loss: 9.6511 - val_accuracy: 0.0197\n",
      "Epoch 32/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 1.9738 - accuracy: 0.5542 - val_loss: 9.7365 - val_accuracy: 0.0157\n",
      "Epoch 33/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 1.8173 - accuracy: 0.6089 - val_loss: 9.8949 - val_accuracy: 0.0157\n",
      "Epoch 34/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 1.6763 - accuracy: 0.6549 - val_loss: 9.9367 - val_accuracy: 0.0157\n",
      "Epoch 35/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 1.5536 - accuracy: 0.6824 - val_loss: 10.0518 - val_accuracy: 0.0157\n",
      "Epoch 36/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 1.4379 - accuracy: 0.7209 - val_loss: 10.0974 - val_accuracy: 0.0118\n",
      "Epoch 37/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 1.3416 - accuracy: 0.7445 - val_loss: 10.2148 - val_accuracy: 0.0157\n",
      "Epoch 38/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 1.2265 - accuracy: 0.7839 - val_loss: 10.3224 - val_accuracy: 0.0197\n",
      "Epoch 39/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 1.1253 - accuracy: 0.8031 - val_loss: 10.3650 - val_accuracy: 0.0118\n",
      "Epoch 40/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 1.0408 - accuracy: 0.8338 - val_loss: 10.5295 - val_accuracy: 0.0118\n",
      "Epoch 41/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.9514 - accuracy: 0.8473 - val_loss: 10.5731 - val_accuracy: 0.0118\n",
      "Epoch 42/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.8817 - accuracy: 0.8718 - val_loss: 10.6128 - val_accuracy: 0.0079\n",
      "Epoch 43/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.8077 - accuracy: 0.8815 - val_loss: 10.6449 - val_accuracy: 0.0118\n",
      "Epoch 44/50\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.7356 - accuracy: 0.9077 - val_loss: 10.7273 - val_accuracy: 0.0118\n",
      "Epoch 45/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.6650 - accuracy: 0.9151 - val_loss: 10.8128 - val_accuracy: 0.0118\n",
      "Epoch 46/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.6150 - accuracy: 0.9213 - val_loss: 10.8589 - val_accuracy: 0.0197\n",
      "Epoch 47/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.5671 - accuracy: 0.9361 - val_loss: 10.9297 - val_accuracy: 0.0197\n",
      "Epoch 48/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.5232 - accuracy: 0.9396 - val_loss: 10.9823 - val_accuracy: 0.0197\n",
      "Epoch 49/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.4690 - accuracy: 0.9497 - val_loss: 11.0031 - val_accuracy: 0.0197\n",
      "Epoch 50/50\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.4195 - accuracy: 0.9598 - val_loss: 11.0571 - val_accuracy: 0.0197\n",
      "\n",
      "Embedding vector for 'कहानी': [ 0.0158189   0.00554636  0.0024846  -0.01385081  0.01686989]\n",
      "\n",
      "Words similar to 'कहानी':\n",
      "कभी: 0.6626\n",
      "कोदिखने: 0.6399\n",
      "कचहरी: 0.6241\n",
      "पढ़ाने: 0.6076\n",
      "वर्षों: 0.6034\n"
     ]
    }
   ],
   "source": [
    "max_sequence_length = 5\n",
    "\n",
    "# Create and train the model\n",
    "rnn_model = train_hindi_rnn_embeddings(\n",
    "    input_tensor_train,\n",
    "    vocab_inp_size,\n",
    "    inp_lang,\n",
    "    max_sequence_length\n",
    ")\n",
    "\n",
    "model = load_model('models/Part2.h5')\n",
    "\n",
    "word = 'कहानी'\n",
    "if word in inp_lang.word_index:\n",
    "    word_idx = inp_lang.word_index[word]\n",
    "\n",
    "    # Find embeddings for the word\n",
    "    embedding = get_word_embedding(model, word_idx)\n",
    "    print(f\"\\nEmbedding vector for '{word}':\", embedding[:5])\n",
    "\n",
    "    # Find other similar words\n",
    "    similar_words = find_similar_words(model, word_idx, tokenizer=inp_lang)\n",
    "    print(f\"\\nWords similar to '{word}':\")\n",
    "    \n",
    "    for similar_word, similarity in similar_words:\n",
    "        print(f\"{similar_word}: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b1e1c9",
   "metadata": {},
   "source": [
    "### Save the word embeddings to a text file\n",
    "\n",
    "- Iterate over the vocabulary in the tokenizer, retrieve the embedding for each word, and write the word along with its embedding vector to the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f90897e0-2a56-422c-a18e-740444545bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings saved to hindi_word_embeddings.txt\n"
     ]
    }
   ],
   "source": [
    "def save_embeddings_to_file(model, tokenizer, file_name='hindi_word_embeddings.txt'):\n",
    "    with open(file_name, 'w', encoding='utf-8') as f:\n",
    "        \n",
    "        # Iterate over each word and its index in the tokenizer vocabulary\n",
    "        for word, idx in tokenizer.word_index.items():\n",
    "            embedding = get_word_embedding(model, idx)\n",
    "            if embedding is not None:\n",
    "                # Convert the embedding vector to a string\n",
    "                embedding_str = ' '.join(map(str, embedding))\n",
    "                f.write(f\"{word} {embedding_str}\\n\")\n",
    "    \n",
    "    print(f\"Embeddings saved to {file_name}\")\n",
    "\n",
    "save_embeddings_to_file(model, inp_lang)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
